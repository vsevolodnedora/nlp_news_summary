name: Scrape

on:
  push:
    branches: ["main"]
  schedule:
    - cron: '0 18 * * *'  # Runs at 18:00 UTC daily

jobs:
  update_data:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'schedule'
    permissions:
      contents: write
    env:
      LOG_LEVEL: WARNING
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11.5'
          cache: 'pipenv'

      - name: Install pipenv
        run: curl https://raw.githubusercontent.com/pypa/pipenv/master/get-pipenv.py | python

      - name: Install Dependencies
        run: pipenv install

      - name: Install Playwright Browsers
        run: pipenv run playwright install

      - name: Scrape Data
        run: pipenv run python run_scrape.py tennet

      - name: Commit Updated Data
        run: |
          git config --global user.name 'Collector'
          git config --global user.email 'noreply@nedora.digital'
          git add database/scraped_posts.db
          git commit -m "Added latest posts to the database"
          git pull -r
          git push
